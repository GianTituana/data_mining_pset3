# üöï NYC Taxi Data Pipeline - Proyecto 03 (Gian Titua√±a)
## Data Mining | Universidad San Francisco de Quito

Pipeline de ingesta y an√°lisis de datos de NYC TLC Trip Records (2015-2025) utilizando Spark, Jupyter y Snowflake con arquitectura One Big Table (OBT).

---

## üìã Tabla de Contenidos

- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [Matriz de Cobertura de Datos](#-matriz-de-cobertura-de-datos)
- [Instalaci√≥n y Configuraci√≥n](#-instalaci√≥n-y-configuraci√≥n)
- [Variables de Entorno](#-variables-de-entorno)
- [Ejecuci√≥n del Pipeline](#-ejecuci√≥n-del-pipeline)
- [Dise√±o de Esquemas](#-dise√±o-de-esquemas)
- [Calidad y Auditor√≠a](#-calidad-y-auditor√≠a)
- [Preguntas de Negocio](#-preguntas-de-negocio)
- [Troubleshooting](#-troubleshooting)
- [Checklist de Aceptaci√≥n](#-checklist-de-aceptaci√≥n)

---

## üèóÔ∏è Arquitectura del Sistema

### Diagrama de Flujo
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      NYC TLC DATA SOURCE                         ‚îÇ
‚îÇ            https://d37ci6vzurychx.cloudfront.net/               ‚îÇ
‚îÇ                   (Parquet Files 2015-2025)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚îÇ HTTP Download
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DOCKER COMPOSE ENVIRONMENT                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ           JUPYTER + PYSPARK NOTEBOOK                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Notebooks:                                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ 01_ingesta_parquet_raw.ipynb                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ 02_enriquecimiento_y_unificacion.ipynb              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ 03_construccion_obt.ipynb                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ 04_validaciones_y_exploracion.ipynb                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ 05_data_analysis.ipynb                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Ports: 8888 (Jupyter), 4040 (Spark UI)                  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚îÇ JDBC Connection
                        ‚îÇ (Snowflake Connector)
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        SNOWFLAKE                                 ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  DATABASE: NY_TAXI                                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  SCHEMA: RAW (Staging Layer)                   ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                                                 ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Tables:                                        ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ yellow_trips_YYYY_MM                      ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ green_trips_YYYY_MM                       ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ taxi_zone_lookup                          ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ audit_log                                 ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                                                 ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Metadata: run_id, source_year, source_month,  ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ            ingested_at_utc, service_type       ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                          ‚îÇ                              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                          ‚îÇ Enrichment & Unification     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                          ‚ñº                              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  SCHEMA: ANALYTICS (Consumption Layer)         ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                                                 ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Table: obt_trips (One Big Table)              ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                                                 ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Grain: 1 row = 1 trip                         ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                                                 ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Columns (70+):                                ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ Time Dimensions (10)                      ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ Location Dimensions (6)                   ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ Service & Codes (8)                       ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ Trip Facts (3)                            ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ Fare Components (9)                       ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ Derived Metrics (3)                       ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ Lineage Metadata (5)                      ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes del Sistema

| Componente | Tecnolog√≠a | Prop√≥sito | Puerto |
|-----------|-----------|-----------|--------|
| **Ingesta & Procesamiento** | PySpark 3.5 | Lectura de Parquet, transformaciones, carga | - |
| **Ambiente de Desarrollo** | Jupyter Notebook | Notebooks interactivos para ETL | 8888 |
| **Monitoreo Spark** | Spark UI | Monitoreo de jobs y performance | 4040 |
| **Data Warehouse** | Snowflake | Almacenamiento persistente (RAW + ANALYTICS) | Cloud |
| **Orquestaci√≥n** | Docker Compose | Gesti√≥n de contenedores y red | - |

### Flujo de Datos

1. **Extracci√≥n**: Descarga de archivos Parquet desde NYC TLC (2015-2025)
2. **Staging (RAW)**: Carga incremental mes a mes con metadatos de lineage
3. **Enriquecimiento**: Join con Taxi Zone Lookup, normalizaci√≥n de cat√°logos
4. **Transformaci√≥n**: C√°lculo de m√©tricas derivadas (duraci√≥n, velocidad, tip_pct)
5. **OBT Construction**: Consolidaci√≥n en tabla desnormalizada √∫nica
6. **Validaci√≥n**: Controles de calidad (rangos, nulos, coherencia)
7. **Analytics**: Consultas de negocio sobre OBT

---

## üìä Matriz de Cobertura de Datos

### Cobertura 2015-2025 (Yellow Taxi)

| A√±o | Ene | Feb | Mar | Abr | May | Jun | Jul | Ago | Sep | Oct | Nov | Dic | Total |
|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-------|
| 2015 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2016 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2017 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2018 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2019 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2020 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2021 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2022 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2023 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2024 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2025 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | 8/12 |

### Cobertura 2015-2025 (Green Taxi)

| A√±o | Ene | Feb | Mar | Abr | May | Jun | Jul | Ago | Sep | Oct | Nov | Dic | Total |
|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-------|
| 2015 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2016 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2017 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2018 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2019 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2020 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2021 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2022 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2023 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2024 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | 12/12 |
| 2025 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | 8/12 |

**Leyenda:**
- ‚úÖ = Datos cargados exitosamente
- ‚ùå = Archivo no disponible o fall√≥ la carga
- ‚è≥ = Datos a√∫n no disponibles (futuro)


## üöÄ Instalaci√≥n y Configuraci√≥n

### Pre-requisitos

- Docker Engine 20.10+
- Docker Compose 2.0+
- 8GB RAM m√≠nimo (16GB recomendado)
- 50GB espacio en disco
- Cuenta de Snowflake activa

### Paso 1: Clonar el Repositorio
```bash
git clone https://github.com/GianTituana/data_mining_pset3.git
cd nyc-taxi-pipeline
```

### Paso 2: Configurar Variables de Entorno
```bash
# Copiar plantilla
cp .env.example .env

# Editar con tus credenciales
nano .env  # o usar tu editor favorito
```

### Paso 3: Estructura de Directorios
```
nyc-taxi-pipeline/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_ingesta_parquet_raw.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_enriquecimiento_y_unificacion.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_construccion_obt.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_validaciones_y_exploracion.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 05_data_analysis.ipynb
‚îú‚îÄ‚îÄ work/
‚îÇ   ‚îî‚îÄ‚îÄ (archivos temporales de Spark)
‚îÇ   ‚îî‚îÄ‚îÄ (notebooks ejecutados sin limpieza de outpus)
‚îî‚îÄ‚îÄ evidencias/
    ‚îú‚îÄ‚îÄ evidencias.md
```

### Paso 4: Levantar la Infraestructura
```bash
# Iniciar contenedores
docker-compose up -d

# Verificar que est√©n corriendo
docker-compose ps

# Ver logs
docker-compose logs -f pyspark-notebook
```

### Paso 5: Acceder a Jupyter


1. Abrir en navegador:
```
http://localhost:8888
```

### Paso 6: Verificar Spark UI
```
http://localhost:4040
```

---

## üîê Variables de Entorno

### Archivo `.env.example` (Plantilla sin credenciales)
```bash
# ===================================
# SNOWFLAKE CONFIGURATION
# ===================================
SNOWFLAKE_ACCOUNT=tu-cuenta.snowflakecomputing.com
SNOWFLAKE_USER=tu_usuario
SNOWFLAKE_PASSWORD=tu_contrase√±a
SNOWFLAKE_DATABASE=NY_TAXI
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
SNOWFLAKE_SCHEMA_RAW=RAW
SNOWFLAKE_SCHEMA_ENRICHED=ENRICHED
SNOWFLAKE_SCHEMA_ANALYTICS=ANALYTICS


# ===================================
# DATA SOURCE
# ===================================
PARQUET_BASE_URL=https://d37ci6vzurychx.cloudfront.net/trip-data
START_YEAR=2015
END_YEAR=2025
SERVICES=yellow,green

### Descripci√≥n de Variables

| Variable | Descripci√≥n | Ejemplo | Obligatoria |
|----------|-------------|---------|-------------|
| **SNOWFLAKE_ACCOUNT** | URL de tu cuenta Snowflake | `abc123.us-east-1` | ‚úÖ |
| **SNOWFLAKE_USER** | Usuario de Snowflake | `mi_usuario` | ‚úÖ |
| **SNOWFLAKE_PASSWORD** | Contrase√±a | `MiPass123!` | ‚úÖ |
| **SNOWFLAKE_DATABASE** | Base de datos | `NY_TAXI` | ‚úÖ |
| **SNOWFLAKE_WAREHOUSE** | Warehouse a usar | `COMPUTE_WH` | ‚úÖ |
| **SNOWFLAKE_SCHEMA_RAW** | Schema de staging | `RAW` | ‚ùå (default: RAW) |
| **SNOWFLAKE_SCHEMA_ANALYTICS** | Schema de analytics | `ANALYTICS` | ‚ùå (default: ANALYTICS) |
| **SNOWFLAKE_ROLE** | Role de Snowflake | `ACCOUNTADMIN` | ‚ùå (default: ACCOUNTADMIN) |
| **PARQUET_BASE_URL** | URL base de datos | `https://...` | ‚ùå (tiene default) |
| **START_YEAR** | A√±o inicial | `2015` | ‚ùå (default: 2015) |
| **END_YEAR** | A√±o final | `2025` | ‚ùå (default: 2025) |

### ‚ö†Ô∏è Seguridad


---

## üîÑ Ejecuci√≥n del Pipeline

### Orden de Ejecuci√≥n de Notebooks

Ejecuta los notebooks en el siguiente orden:

#### 1Ô∏è‚É£ **01_ingesta_parquet_raw.ipynb**

**Prop√≥sito:** Descarga e ingesta de archivos Parquet a schema RAW

**Par√°metros configurables:**
```python
START_YEAR = 2015
END_YEAR = 2025
SERVICES = ['yellow', 'green']
```

**Tiempo estimado:** 2-7 horas (depende de red y tama√±o y servicio)

**Salida:**
- Tablas: `raw.yellow_trips_YYYY_MM`, `raw.green_trips_YYYY_MM`
- Metadatos: run_id, service_type, source_year, source_month, ingested_at_utc

**Validaciones:**
- Conteo de registros por archivo
- Verificaci√≥n de columnas esperadas
- Log de errores de descarga

---

#### 2Ô∏è‚É£ **02_enriquecimiento_y_unificacion.ipynb**

**Prop√≥sito:** Enriquecer con Taxi Zones y unificar esquemas Yellow/Green

**Par√°metros configurables:**
```python
SCHEMA_RAW = 'RAW'
```

**Tiempo estimado:** 30-60 minutos

**Transformaciones:**
- Join con `taxi_zone_lookup` para nombres de zonas/boroughs
- Normalizaci√≥n de cat√°logos (vendor, payment_type, rate_code)
- Unificaci√≥n de columnas Yellow/Green

**Salida:**
- Tablas intermedias enriquecidas en RAW

---

#### 3Ô∏è‚É£ **03_construccion_obt.ipynb**

**Prop√≥sito:** Construir la One Big Table (OBT) en ANALYTICS

**Par√°metros configurables:**
```python
SCHEMA_ANALYTICS = 'ANALYTICS'
RUN_ID = 'run_20250119_001'
REBUILD_MODE = 'full'  # o 'incremental'
```

**Tiempo estimado:** 1-2 horas

**Derivadas calculadas:**
```sql
trip_duration_min = (dropoff_datetime - pickup_datetime) / 60
avg_speed_mph = trip_distance / (trip_duration_min / 60)
tip_pct = (tip_amount / fare_amount) * 100
```

**Salida:**
- Tabla: `analytics.obt_trips`
- Grano: 1 fila = 1 viaje

**Verificaci√≥n de idempotencia:**
- Re-ejecutar con mismo RUN_ID no duplica datos
- Estrategia: MERGE basado en clave natural

---

#### 4Ô∏è‚É£ **04_validaciones_y_exploracion.ipynb**

**Prop√≥sito:** Validar calidad de datos y exploraci√≥n inicial

**Validaciones implementadas:**
- ‚úÖ Nulos en columnas cr√≠ticas (pickup_datetime, location_id)
- ‚úÖ Rangos l√≥gicos (distancia ‚â• 0, duraci√≥n > 0)
- ‚úÖ Coherencia de fechas (dropoff > pickup)
- ‚úÖ Montos positivos (fare_amount, total_amount)
- ‚úÖ Consistencia de sumas (total_amount vs componentes)

**Tiempo estimado:** 15-30 minutos

**Reportes generados:**
- Conteo de nulos por columna
- Estad√≠sticas descriptivas
- Outliers identificados
- M√©tricas de calidad

---

#### 5Ô∏è‚É£ **05_data_analysis.ipynb**

**Prop√≥sito:** Responder 20 preguntas de negocio

**Tiempo estimado:** 30-45 minutos

**Preguntas cubiertas:** Ver secci√≥n [Preguntas de Negocio](#-preguntas-de-negocio)

---

## üóÑÔ∏è Dise√±o de Esquemas

### Schema RAW (Staging Layer)

#### Prop√≥sito
Aterrizaje espejo del origen con metadatos m√≠nimos de lineage.

#### Tablas

##### `raw.yellow_taxi`

| Columna | Tipo | Descripci√≥n | Origen |
|---------|------|-------------|--------|
| `VendorID` | INTEGER | Proveedor (1=Creative, 2=VeriFone) | Parquet |
| `tpep_pickup_datetime` | TIMESTAMP | Fecha/hora de pickup | Parquet |
| `tpep_dropoff_datetime` | TIMESTAMP | Fecha/hora de dropoff | Parquet |
| `passenger_count` | INTEGER | N√∫mero de pasajeros | Parquet |
| `trip_distance` | DOUBLE | Distancia en millas | Parquet |
| `RatecodeID` | INTEGER | C√≥digo de tarifa | Parquet |
| `store_and_fwd_flag` | STRING | Flag de almacenamiento | Parquet |
| `PULocationID` | INTEGER | ID zona de pickup | Parquet |
| `DOLocationID` | INTEGER | ID zona de dropoff | Parquet |
| `payment_type` | INTEGER | Tipo de pago | Parquet |
| `fare_amount` | DOUBLE | Tarifa base | Parquet |
| `extra` | DOUBLE | Extras (rush hour, overnight) | Parquet |
| `mta_tax` | DOUBLE | Impuesto MTA | Parquet |
| `tip_amount` | DOUBLE | Propina | Parquet |
| `tolls_amount` | DOUBLE | Peajes | Parquet |
| `improvement_surcharge` | DOUBLE | Recargo de mejora | Parquet |
| `total_amount` | DOUBLE | Monto total | Parquet |
| `congestion_surcharge` | DOUBLE | Recargo por congesti√≥n | Parquet |
| `airport_fee` | DOUBLE | Tarifa de aeropuerto | Parquet |
| **`run_id`** | STRING | ID de ejecuci√≥n | **Generado** |
| **`service_type`** | STRING | 'yellow' | **Generado** |
| **`source_year`** | INTEGER | A√±o del archivo | **Generado** |
| **`source_month`** | INTEGER | Mes del archivo | **Generado** |
| **`ingested_at_utc`** | TIMESTAMP | Timestamp de ingesta | **Generado** |
| **`source_path`** | STRING | URL del Parquet | **Generado** |

##### `raw.green_taxi`

Misma estructura que Yellow, con diferencias:
- `lpep_pickup_datetime` / `lpep_dropoff_datetime` (en lugar de tpep)
- `trip_type` adicional (1=Street-hail, 2=Dispatch)
- `service_type` = 'green'

##### `raw.taxi_zone_lookup`

| Columna | Tipo | Descripci√≥n |
|---------|------|-------------|
| `LocationID` | INTEGER | ID √∫nico de zona |
| `Borough` | STRING | Manhattan, Brooklyn, Queens, Bronx, Staten Island, EWR |
| `Zone` | STRING | Nombre espec√≠fico de la zona |
| `service_zone` | STRING | Yellow Zone, Boro Zone, Airports, etc. |

---

### Schema ENRICHED (ENRICHMENT Layer)

#### Tabla: `aenriched.unified_taxi_enriched`

### Schema ANALYTICS (Consumption Layer)

#### Tabla: `analytics.obt_trips`

**Grano:** 1 fila = 1 viaje

**Estrategia de desnormalizaci√≥n:** One Big Table (OBT) con todas las dimensiones embebidas

#### Columnas de la OBT (70+ columnas)

##### üìÖ **Dimensiones de Tiempo** (10 columnas)

| Columna | Tipo | Descripci√≥n | L√≥gica |
|---------|------|-------------|--------|
| `pickup_datetime` | TIMESTAMP | Fecha/hora completa de pickup | Del RAW |
| `dropoff_datetime` | TIMESTAMP | Fecha/hora completa de dropoff | Del RAW |
| `pickup_date` | DATE | Solo fecha de pickup | `CAST(pickup_datetime AS DATE)` |
| `dropoff_date` | DATE | Solo fecha de dropoff | `CAST(dropoff_datetime AS DATE)` |

## Consideraciones finales

‚úÖDocker Compose levanta Spark y Jupyter Notebook.
‚úÖTodas las credenciales/par√°metros provienen de variables de ambiente (.env).
‚úÖCobertura 2015‚Äì2025 (Yellow/Green) cargada en raw con matriz y conteos por lote.
‚úÖanalytics.obt_trips creada con columnas m√≠nimas, derivadas y metadatos.
‚úÖIdempotencia verificada reingestando al menos un mes.
‚úÖValidaciones b√°sicas documentadas (nulos, rangos, coherencia).
‚úÖ20 preguntas respondidas (texto) usando la OBT.
‚úÖREADME claro: pasos, variables, esquema, decisiones, troubleshooting.